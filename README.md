# Scraper de livres â€“ Books to Scrape

## 1. Objectif du projet

Ce projet consiste Ã  dÃ©velopper un scraper Python pour extraire des informations sur des livres depuis le site [Books to Scrape](https://books.toscrape.com/). Lâ€™objectif est de rÃ©cupÃ©rer automatiquement les donnÃ©es des livres (titre, prix, note, stock, UPC, catÃ©gorie, URL, image) et de les sauvegarder dans des fichiers CSV, tout en tÃ©lÃ©chargeant les images associÃ©es dans des dossiers organisÃ©s par catÃ©gorie.

Le projet permet Ã©galement de :

* GÃ©rer la pagination pour rÃ©cupÃ©rer tous les livres dâ€™une catÃ©gorie.
* Limiter le nombre de pages scrappÃ©es pour des tests rapides.
* Ajouter un dÃ©lai entre les requÃªtes pour Ã©viter de surcharger le site.
* SÃ©lectionner une ou plusieurs catÃ©gories Ã  scraper via la ligne de commande.
* Organiser les donnÃ©es et images dans des dossiers spÃ©cifiques.

---

## 2. PrÃ©requis et installation

### PrÃ©requis

* Python 3.10 ou supÃ©rieur
* Connexion internet pour accÃ©der au site cible

### Installation

1. Cloner le dÃ©pÃ´t ou copier le projet sur votre machine.
2. CrÃ©er un environnement virtuel (recommandÃ©) :

```bash
python -m venv venv
```

3. Activer lâ€™environnement virtuel :

* **Windows** :

```bash
venv\Scripts\activate
```

* **Linux / macOS** :

```bash
source venv/bin/activate
```

4. Installer les dÃ©pendances :

```bash
pip install -r requirements.txt
```

> Le fichier `requirements.txt` contient toutes les bibliothÃ¨ques nÃ©cessaires : `requests`, `parsel`, etc.

---

## 3. Structure du projet

```
project/
â”œâ”€â”€ scrape.py          # Script principal pour lancer le scraping
â”œâ”€â”€ parsers.py         # Fonctions pour parser les pages et catÃ©gories
â”œâ”€â”€ utils.py           # Fonctions utilitaires (CSV, tÃ©lÃ©chargement images, dossiers)
â”œâ”€â”€ settings.py        # ParamÃ¨tres du projet (URL, headers, dÃ©lais)
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ csv/           # CSV gÃ©nÃ©rÃ©s par catÃ©gorie
â”‚   â””â”€â”€ images/        # Images tÃ©lÃ©chargÃ©es par catÃ©gorie
â”œâ”€â”€ README.md          # Documentation du projet
â””â”€â”€ requirements.txt   # DÃ©pendances Python
```

---

## 4. Utilisation du scraper

### Commandes de base

* Scraper une seule catÃ©gorie :

```bash
python scrape.py --categories Travel
```

* Scraper plusieurs catÃ©gories (sÃ©parÃ©es par une virgule) :

```bash
python scrape.py --categories Travel,Poetry
```

* Limiter le nombre de pages pour tester rapidement :

```bash
python scrape.py --categories Travel --max-pages 1
```

* Ajouter un dÃ©lai entre les requÃªtes pour rÃ©duire la charge serveur :

```bash
python scrape.py --categories Travel --delay 1
```

* Modifier le dossier de sortie pour les CSV et images :

```bash
python scrape.py --categories Travel --outdir outputs
```

---

### 5. RÃ©sultat attendu

AprÃ¨s exÃ©cution, le projet gÃ©nÃ¨re :

1. **Fichiers CSV** :

```
outputs/csv/category_travel.csv
```

Contenant : Titre, Prix, Note, URL, Image, Stock, UPC, CatÃ©gorie

2. **Images tÃ©lÃ©chargÃ©es** :

```
outputs/images/travel/<UPC>_<slug-title>.jpg
```

Exemple de sortie console :

```
ğŸš€ Starting category: Travel
ğŸ” Scraping page: https://books.toscrape.com/catalogue/category/books/travel_2/index.html
ğŸ“¥ Downloading image: https://books.toscrape.com/catalogue/media/cache/3e/ef/3eef99c9d9f93c8f1a0d0d2b7f1d03c1.jpg -> outputs/images/travel/a897_Its_Only_the_Himalayas.jpg
ğŸ“¸ Image saved: outputs/images/travel/a897_Its_Only_the_Himalayas.jpg
âœ… [Travel] Saved: It's Only the Himalayas
ğŸ’¾ Category saved to: outputs/csv/category_travel.csv
```

---

## 6. Notes importantes

* Respectez les dÃ©lais pour ne pas surcharger le site web.
* Les noms de fichiers sont sÃ©curisÃ©s pour Ã©viter les caractÃ¨res invalides.
* Chaque catÃ©gorie possÃ¨de son propre sous-dossier pour les images et CSV.

---
